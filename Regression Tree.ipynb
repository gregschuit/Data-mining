{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression Tree\n",
    "Gregory Schuit - 16636910"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('data/FATS_GAIA.dat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Amplitude</th>\n",
       "      <th>AndersonDarling</th>\n",
       "      <th>Autocor_length</th>\n",
       "      <th>Class</th>\n",
       "      <th>Con</th>\n",
       "      <th>Eta_e</th>\n",
       "      <th>FluxPercentileRatioMid20</th>\n",
       "      <th>FluxPercentileRatioMid35</th>\n",
       "      <th>FluxPercentileRatioMid50</th>\n",
       "      <th>FluxPercentileRatioMid65</th>\n",
       "      <th>...</th>\n",
       "      <th>PeriodLS</th>\n",
       "      <th>Period_fit</th>\n",
       "      <th>Psi_CS</th>\n",
       "      <th>Psi_eta</th>\n",
       "      <th>Q31</th>\n",
       "      <th>Rcs</th>\n",
       "      <th>Skew</th>\n",
       "      <th>SlottedA_length</th>\n",
       "      <th>SmallKurtosis</th>\n",
       "      <th>Std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.416432</td>\n",
       "      <td>0.949482</td>\n",
       "      <td>3.0</td>\n",
       "      <td>MIRA_SR</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.442293</td>\n",
       "      <td>0.243054</td>\n",
       "      <td>0.462373</td>\n",
       "      <td>0.653511</td>\n",
       "      <td>0.761790</td>\n",
       "      <td>...</td>\n",
       "      <td>268.331543</td>\n",
       "      <td>0.025528</td>\n",
       "      <td>0.304804</td>\n",
       "      <td>0.310355</td>\n",
       "      <td>1.784879</td>\n",
       "      <td>0.304804</td>\n",
       "      <td>0.011895</td>\n",
       "      <td>19.899170</td>\n",
       "      <td>-1.266215</td>\n",
       "      <td>0.931676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.443386</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>RRAB</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>12042.752633</td>\n",
       "      <td>0.162446</td>\n",
       "      <td>0.231268</td>\n",
       "      <td>0.517775</td>\n",
       "      <td>0.720122</td>\n",
       "      <td>...</td>\n",
       "      <td>0.508910</td>\n",
       "      <td>0.012390</td>\n",
       "      <td>0.309458</td>\n",
       "      <td>0.519645</td>\n",
       "      <td>0.397205</td>\n",
       "      <td>0.258203</td>\n",
       "      <td>-0.962335</td>\n",
       "      <td>0.147949</td>\n",
       "      <td>-0.183573</td>\n",
       "      <td>0.284637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.170099</td>\n",
       "      <td>0.875986</td>\n",
       "      <td>4.0</td>\n",
       "      <td>MIRA_SR</td>\n",
       "      <td>0.030303</td>\n",
       "      <td>137.020266</td>\n",
       "      <td>0.033964</td>\n",
       "      <td>0.208724</td>\n",
       "      <td>0.378623</td>\n",
       "      <td>0.501416</td>\n",
       "      <td>...</td>\n",
       "      <td>8.742769</td>\n",
       "      <td>0.040022</td>\n",
       "      <td>0.342646</td>\n",
       "      <td>0.700200</td>\n",
       "      <td>0.119849</td>\n",
       "      <td>0.368936</td>\n",
       "      <td>0.472161</td>\n",
       "      <td>0.147949</td>\n",
       "      <td>0.064528</td>\n",
       "      <td>0.089020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.350858</td>\n",
       "      <td>0.999869</td>\n",
       "      <td>4.0</td>\n",
       "      <td>MIRA_SR</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>23.583559</td>\n",
       "      <td>0.259476</td>\n",
       "      <td>0.593270</td>\n",
       "      <td>0.613808</td>\n",
       "      <td>0.817245</td>\n",
       "      <td>...</td>\n",
       "      <td>379.949707</td>\n",
       "      <td>0.000843</td>\n",
       "      <td>0.349687</td>\n",
       "      <td>0.285682</td>\n",
       "      <td>1.867060</td>\n",
       "      <td>0.349687</td>\n",
       "      <td>-0.047072</td>\n",
       "      <td>23.597900</td>\n",
       "      <td>-1.454570</td>\n",
       "      <td>0.926506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.248472</td>\n",
       "      <td>0.999947</td>\n",
       "      <td>3.0</td>\n",
       "      <td>MIRA_SR</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>125.486491</td>\n",
       "      <td>0.202240</td>\n",
       "      <td>0.448444</td>\n",
       "      <td>0.565120</td>\n",
       "      <td>0.606539</td>\n",
       "      <td>...</td>\n",
       "      <td>318.427795</td>\n",
       "      <td>0.022169</td>\n",
       "      <td>0.247451</td>\n",
       "      <td>0.578087</td>\n",
       "      <td>0.273482</td>\n",
       "      <td>0.247451</td>\n",
       "      <td>0.594605</td>\n",
       "      <td>0.147949</td>\n",
       "      <td>-0.689124</td>\n",
       "      <td>0.153349</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 56 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Amplitude  AndersonDarling  Autocor_length    Class       Con  \\\n",
       "0   1.416432         0.949482             3.0  MIRA_SR  0.000000   \n",
       "1   0.443386         1.000000             1.0     RRAB  0.000000   \n",
       "2   0.170099         0.875986             4.0  MIRA_SR  0.030303   \n",
       "3   1.350858         0.999869             4.0  MIRA_SR  0.000000   \n",
       "4   0.248472         0.999947             3.0  MIRA_SR  0.000000   \n",
       "\n",
       "          Eta_e  FluxPercentileRatioMid20  FluxPercentileRatioMid35  \\\n",
       "0      5.442293                  0.243054                  0.462373   \n",
       "1  12042.752633                  0.162446                  0.231268   \n",
       "2    137.020266                  0.033964                  0.208724   \n",
       "3     23.583559                  0.259476                  0.593270   \n",
       "4    125.486491                  0.202240                  0.448444   \n",
       "\n",
       "   FluxPercentileRatioMid50  FluxPercentileRatioMid65    ...       PeriodLS  \\\n",
       "0                  0.653511                  0.761790    ...     268.331543   \n",
       "1                  0.517775                  0.720122    ...       0.508910   \n",
       "2                  0.378623                  0.501416    ...       8.742769   \n",
       "3                  0.613808                  0.817245    ...     379.949707   \n",
       "4                  0.565120                  0.606539    ...     318.427795   \n",
       "\n",
       "   Period_fit    Psi_CS   Psi_eta       Q31       Rcs      Skew  \\\n",
       "0    0.025528  0.304804  0.310355  1.784879  0.304804  0.011895   \n",
       "1    0.012390  0.309458  0.519645  0.397205  0.258203 -0.962335   \n",
       "2    0.040022  0.342646  0.700200  0.119849  0.368936  0.472161   \n",
       "3    0.000843  0.349687  0.285682  1.867060  0.349687 -0.047072   \n",
       "4    0.022169  0.247451  0.578087  0.273482  0.247451  0.594605   \n",
       "\n",
       "   SlottedA_length  SmallKurtosis       Std  \n",
       "0        19.899170      -1.266215  0.931676  \n",
       "1         0.147949      -0.183573  0.284637  \n",
       "2         0.147949       0.064528  0.089020  \n",
       "3        23.597900      -1.454570  0.926506  \n",
       "4         0.147949      -0.689124  0.153349  \n",
       "\n",
       "[5 rows x 56 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(160535, 40134)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(123)\n",
    "shuffled = data.loc[np.random.permutation(data.index)]\n",
    "\n",
    "percentil80 = int(len(data)*0.8)\n",
    "train = shuffled[:percentil80]\n",
    "test = shuffled[percentil80:]\n",
    "\n",
    "len(train), len(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node:\n",
    "    \"\"\"\n",
    "    EDD principal para generar el árbol de regresión.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, feature=None, division_point=None, leaf=False, data=None):\n",
    "        self.left_child = None  # de la clase Node\n",
    "        self.right_child = None  # de la clase Node\n",
    "        self.feature = feature  # Atributo que instancian sus hijos\n",
    "        self.division_point = division_point  # punto de division que separa a sus hijos\n",
    "        self.leaf = leaf  # Indica si es un nodo hoja\n",
    "        self.data = data  # Si es que es un nodo hoja, contiene las particiones de los datos\n",
    "        \n",
    "    @property\n",
    "    def depth(self):\n",
    "        d = 0\n",
    "        if self.left_child:\n",
    "            d = 1 + self.left_child.depth\n",
    "        if self.right_child:\n",
    "            d = max(d, 1 + self.right_child.depth)\n",
    "        return d\n",
    "    \n",
    "    @property\n",
    "    def number_of_leaves(self):\n",
    "        if self.leaf:\n",
    "            return 1\n",
    "        return self.left_child.number_of_leaves + self.right_child.number_of_leaves\n",
    "    \n",
    "    @property\n",
    "    def total_var(self):\n",
    "        if self.leaf:\n",
    "            return self.data['PeriodLS'].var(ddof=0)\n",
    "        return self.left_child.total_var + self.right_child.total_var\n",
    "        \n",
    "    def __repr__(self):\n",
    "        if not self.leaf:\n",
    "            ret = \"feature: {}\\ndivision_point: {}\\ndepth: {}\\nleaves: {}\".format(self.feature,\n",
    "                                                                                  self.division_point,\n",
    "                                                                                  self.depth,\n",
    "                                                                                  self.number_of_leaves)\n",
    "        else:\n",
    "            ret = \"Hoja\\nNúmero de datos: {}\\nMean: {}\\nstd: {}\".format(len(self.data),\n",
    "                                                                        self.data.mean(),\n",
    "                                                                        self.data.std(ddof=0))\n",
    "        return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "def best_division_point(data, feature, target):\n",
    "    \"\"\"\n",
    "    Calcula las varianzas de manera incremental para cada dato como punto divisorio\n",
    "    de los datos y entrega el index del que minimiza la varianza.\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"Computing best division point for feature {}...                 \".format(feature), end='\\r')\n",
    "    t0 = time()\n",
    "    \n",
    "    if len(data[feature].unique()) == 1:  # si todos los valores de feature son iguales, como podria pasar con Autocor_length\n",
    "        return 0, float('inf'), 0\n",
    "    \n",
    "    # Ordenamos los datos según la feature\n",
    "    ordered = data.sort_values(feature)\n",
    "    total = len(ordered)\n",
    "        \n",
    "    # Valores iniciales\n",
    "    mu_left = ordered[target][:1].mean()\n",
    "    mu_sq_left = sum(x**2 for x in ordered[target][:1]) / 1\n",
    "    var_left = mu_sq_left - mu_left**2\n",
    "\n",
    "    mu_right = ordered[target][1:].mean()\n",
    "    mu_sq_right = sum(x**2 for x in ordered[target][1:]) / (total-1)\n",
    "    var_right = mu_sq_right - mu_right**2\n",
    "\n",
    "    minVar = (var_left + (total-1)*(var_right)) / total\n",
    "    best_point = 0\n",
    "\n",
    "    # Iteramos para recalcular las varianzas según punto de división\n",
    "    columna = [x for x in ordered[feature]]  # para evitar usar iloc, que es muy muy lento\n",
    "    dato_anterior = columna[0]\n",
    "    for i, dato in enumerate(ordered[target][1:-2]):\n",
    "        # si es que el valor se repite, no se considera, para que la particion no divida datos iguales.\n",
    "\n",
    "        mu_left = (mu_left * (i+1) + dato) / (i+2)\n",
    "        mu_sq_left = (mu_sq_left * (i+1) + dato**2) / (i+2)\n",
    "        var_left = mu_sq_left - mu_left**2\n",
    "\n",
    "        mu_right = (mu_right * (total-i-1) - dato) / (total-i-2)\n",
    "        mu_sq_right = (mu_sq_right * (total-i-1) - dato**2) / (total-i-2)\n",
    "        var_right = mu_sq_right - mu_right**2\n",
    "\n",
    "        # sumamos la varianza ponderada de cada partición\n",
    "        var = ((i+2)*(var_left) + (total-i-2)*(var_right)) / total\n",
    "        \n",
    "        if var < minVar:\n",
    "            if columna[i + 1] == dato_anterior:\n",
    "                continue        \n",
    "            minVar = var\n",
    "            best_point = i  # Almacenamos el número del dato\n",
    "        \n",
    "        dato_anterior = columna[i + 1]\n",
    "        \n",
    "    \n",
    "    # retornamos el index del mejor punto de división junto con la varianza obtenidax\n",
    "    idxs_left = [ordered.index[idx] for idx in range(best_point + 1)]\n",
    "    idxs_right = [ordered.index[idx] for idx in range(best_point + 1, len(ordered))]\n",
    "    \n",
    "    # print(\"Best division point founded for {} in {:.4f} seconds.\".format(feature, time() - t0))\n",
    "    return ordered.index[best_point], minVar, [idxs_left, idxs_right]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepoda(datos):\n",
    "    if len(datos) < len(data)*0.05:\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def fit(data, target, max_depth=None):\n",
    "    \"\"\"\n",
    "    Función recursiva para generar el árbol de regresión óptimo.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Condición de término:\n",
    "    if max_depth == 0 or prepoda(data):\n",
    "        hoja = Node(leaf=True)\n",
    "        hoja.data = data\n",
    "        return hoja\n",
    "    \n",
    "    t0 = time()\n",
    "    print(\"Computing best feature... Depth: {}\".format(max_depth))\n",
    "    \n",
    "    features = [col for col in data.columns if col != target and type(data[col].iloc[0]) != str]\n",
    "\n",
    "    best_feature = features[0]\n",
    "    best_point, minVar, best_idxs = best_division_point(data, best_feature, target)\n",
    "    for feature in features[1:]:\n",
    "        point, var, idxs = best_division_point(data, feature, target)\n",
    "        if var < minVar:\n",
    "            best_feature = feature\n",
    "            best_point = point\n",
    "            minVar = var\n",
    "            best_idxs = idxs  # filas de la particion\n",
    "    \n",
    "    print(\"Best feature found in {:.4f} seconds: {}, division_point: {}.\".format(time() - t0, best_feature, best_point))\n",
    "    \n",
    "    print(\"Creating childs...\")\n",
    "    root = Node(feature=best_feature, division_point=data[best_feature][best_point])\n",
    "    \n",
    "    left_data = data.loc[best_idxs[0]]\n",
    "    right_data = data.loc[best_idxs[1]]\n",
    "    \n",
    "    root.left_child = fit(left_data, target, max_depth - 1 if max_depth else None)\n",
    "    print(\"Left child ready. Current time: {:.4f} seconds\".format(time() - t0))\n",
    "    root.right_child = fit(right_data, target, max_depth - 1 if max_depth else None)\n",
    "    print(\"Right child ready. Current time: {:.4f} seconds\".format(time() - t0))\n",
    "    \n",
    "    return root   \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(row, tree, target='PeriodLS'):\n",
    "    \"\"\"\n",
    "    Recorre un árbol de regresión para predecir la clase del dato entregado.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Buscamos la hoja\n",
    "    while not tree.leaf:\n",
    "        if row[tree.feature] < tree.division_point:\n",
    "            tree = tree.left_child\n",
    "        else:\n",
    "            tree = tree.right_child\n",
    "    \n",
    "    # Predecimos en base a lo que haya en la hoja\n",
    "    return tree.data[target].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "def post_poda(self, full_tree):\n",
    "    pass\n",
    "    \"\"\"\n",
    "    for \n",
    "    \"\"\"\n",
    "    # minimize(Sum(Varianzas) + alpha*tree.number_of_leaves)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing best feature... Depth: 20\n",
      "Best feature found in 44.7202 seconds: Autocor_length, division_point: 25935.                \n",
      "Creating childs...\n",
      "Computing best feature... Depth: 19\n",
      "Best feature found in 30.5604 seconds: Eta_e, division_point: 63864.                         \n",
      "Creating childs...\n",
      "Computing best feature... Depth: 18\n",
      "Best feature found in 4.2821 seconds: Freq1_harmonics_amplitude_0, division_point: 129286.   \n",
      "Creating childs...\n",
      "Computing best feature... Depth: 17\n",
      "Best feature found in 3.5471 seconds: Psi_eta, division_point: 94091.                        \n",
      "Creating childs...\n",
      "Left child ready. Current time: 3.5666 seconds\n",
      "Right child ready. Current time: 3.5667 seconds\n",
      "Left child ready. Current time: 7.8751 seconds\n",
      "Right child ready. Current time: 7.8751 seconds\n",
      "Left child ready. Current time: 38.5887 seconds\n",
      "Computing best feature... Depth: 18\n",
      "Best feature found in 26.8885 seconds: Freq3_harmonics_amplitude_0, division_point: 165517.  \n",
      "Creating childs...\n",
      "Computing best feature... Depth: 17\n",
      "Best feature found in 26.7025 seconds: Autocor_length, division_point: 63187.                \n",
      "Creating childs...\n",
      "Computing best feature... Depth: 16\n",
      "Best feature found in 22.1098 seconds: Freq3_harmonics_amplitude_2, division_point: 151959.  \n",
      "Creating childs...\n",
      "Computing best feature... Depth: 15\n",
      "Best feature found in 22.7822 seconds: Freq1_harmonics_amplitude_0, division_point: 162821.  \n",
      "Creating childs...\n",
      "Computing best feature... Depth: 14\n",
      "Best feature found in 22.5611 seconds: Freq3_harmonics_amplitude_3, division_point: 84626.   \n",
      "Creating childs...\n",
      "Computing best feature... Depth: 13\n",
      "Best feature found in 22.7568 seconds: Mean, division_point: 94505.                          \n",
      "Creating childs...\n",
      "Computing best feature... Depth: 12\n",
      "Best feature found in 20.4886 seconds: Mean, division_point: 140210.                         \n",
      "Creating childs...\n",
      "Left child ready. Current time: 20.5856 seconds\n",
      "Computing best feature... Depth: 11\n",
      "Best feature found in 20.3918 seconds: Freq2_harmonics_amplitude_0, division_point: 47642.   \n",
      "Creating childs...\n",
      "Computing best feature... Depth: 10\n",
      "Best feature found in 19.1964 seconds: Eta_e, division_point: 145389.                        \n",
      "Creating childs...\n",
      "Left child ready. Current time: 19.2976 seconds\n",
      "Computing best feature... Depth: 9\n",
      "Best feature found in 19.4689 seconds: SlottedA_length, division_point: 183021.              \n",
      "Creating childs...\n",
      "Computing best feature... Depth: 8\n",
      "Best feature found in 17.8066 seconds: Mean, division_point: 152569.                         \n",
      "Creating childs...\n",
      "Left child ready. Current time: 17.8940 seconds\n",
      "Computing best feature... Depth: 7\n",
      "Best feature found in 17.7860 seconds: Psi_eta, division_point: 79849.                       \n",
      "Creating childs...\n",
      "Computing best feature... Depth: 6\n",
      "Best feature found in 13.4552 seconds: FluxPercentileRatioMid50, division_point: 144631.     \n",
      "Creating childs...\n",
      "Left child ready. Current time: 13.5306 seconds\n",
      "Computing best feature... Depth: 5\n",
      "Best feature found in 13.5791 seconds: Skew, division_point: 190941.                         \n",
      "Creating childs...\n",
      "Computing best feature... Depth: 4\n",
      "Best feature found in 13.2530 seconds: MaxSlope, division_point: 182505.                     \n",
      "Creating childs...\n",
      "Left child ready. Current time: 13.3230 seconds\n",
      "Computing best feature... Depth: 3\n",
      "Best feature found in 12.5366 seconds: Con, division_point: 176451.                          \n",
      "Creating childs...\n",
      "Left child ready. Current time: 12.5927 seconds\n",
      "Computing best feature... Depth: 2\n",
      "Best feature found in 12.5021 seconds: Period_fit, division_point: 93790.                    \n",
      "Creating childs...\n",
      "Computing best feature... Depth: 1\n",
      "Best feature found in 9.5832 seconds: FluxPercentileRatioMid50, division_point: 137967.      \n",
      "Creating childs...\n",
      "Left child ready. Current time: 9.6408 seconds\n",
      "Right child ready. Current time: 9.6413 seconds\n",
      "Left child ready. Current time: 22.2110 seconds\n",
      "Right child ready. Current time: 22.2116 seconds\n",
      "Right child ready. Current time: 34.8062 seconds\n",
      "Right child ready. Current time: 48.1314 seconds\n",
      "Left child ready. Current time: 61.7876 seconds\n",
      "Right child ready. Current time: 61.7877 seconds\n",
      "Right child ready. Current time: 75.3247 seconds\n",
      "Left child ready. Current time: 93.2120 seconds\n",
      "Computing best feature... Depth: 6\n",
      "Best feature found in 4.7626 seconds: MaxSlope, division_point: 141020.                      \n",
      "Creating childs...\n",
      "Left child ready. Current time: 4.7889 seconds\n",
      "Computing best feature... Depth: 5\n",
      "Best feature found in 4.7561 seconds: MaxSlope, division_point: 102117.                      \n",
      "Creating childs...\n",
      "Left child ready. Current time: 4.7778 seconds\n",
      "Computing best feature... Depth: 4\n",
      "Best feature found in 4.6758 seconds: Skew, division_point: 195233.                          \n",
      "Creating childs...\n",
      "Left child ready. Current time: 4.7031 seconds\n",
      "Computing best feature... Depth: 3\n",
      "Best feature found in 4.7658 seconds: Psi_eta, division_point: 152853.                       \n",
      "Creating childs...\n",
      "Computing best feature... Depth: 2\n",
      "Best feature found in 4.4565 seconds: Eta_e, division_point: 189069.                         \n",
      "Creating childs...\n",
      "Left child ready. Current time: 4.4810 seconds\n",
      "Computing best feature... Depth: 1\n",
      "Best feature found in 4.1463 seconds: Mean, division_point: 193940.                          \n",
      "Creating childs...\n",
      "Left child ready. Current time: 4.1710 seconds\n",
      "Right child ready. Current time: 4.1711 seconds\n",
      "Right child ready. Current time: 8.6527 seconds\n",
      "Left child ready. Current time: 13.4491 seconds\n",
      "Right child ready. Current time: 13.4492 seconds\n",
      "Right child ready. Current time: 18.1529 seconds\n",
      "Right child ready. Current time: 22.9315 seconds\n",
      "Right child ready. Current time: 27.7211 seconds\n",
      "Right child ready. Current time: 120.9339 seconds\n",
      "Right child ready. Current time: 138.8304 seconds\n",
      "Left child ready. Current time: 158.4043 seconds\n",
      "Right child ready. Current time: 158.4044 seconds\n",
      "Right child ready. Current time: 177.7045 seconds\n",
      "Left child ready. Current time: 198.2051 seconds\n",
      "Right child ready. Current time: 198.2053 seconds\n",
      "Right child ready. Current time: 218.7937 seconds\n",
      "Left child ready. Current time: 241.6878 seconds\n",
      "Right child ready. Current time: 241.6887 seconds\n",
      "Left child ready. Current time: 264.3767 seconds\n",
      "Right child ready. Current time: 264.3768 seconds\n",
      "Left child ready. Current time: 287.2915 seconds\n",
      "Right child ready. Current time: 287.2920 seconds\n",
      "Left child ready. Current time: 309.5152 seconds\n",
      "Right child ready. Current time: 309.5154 seconds\n",
      "Left child ready. Current time: 336.3518 seconds\n",
      "Computing best feature... Depth: 16\n",
      "Best feature found in 3.3147 seconds: PercentDifferenceFluxPercentile, division_point: 164738.\n",
      "Creating childs...\n",
      "Left child ready. Current time: 3.3331 seconds\n",
      "Computing best feature... Depth: 15\n",
      "Best feature found in 3.4523 seconds: Freq2_harmonics_amplitude_0, division_point: 866.      \n",
      "Creating childs...\n",
      "Computing best feature... Depth: 14\n",
      "Best feature found in 3.2435 seconds: Mean, division_point: 149005.                          \n",
      "Creating childs...\n",
      "Computing best feature... Depth: 13\n",
      "Best feature found in 2.7665 seconds: Psi_eta, division_point: 120506.                       \n",
      "Creating childs...\n",
      "Left child ready. Current time: 2.7834 seconds\n",
      "Right child ready. Current time: 2.7835 seconds\n",
      "Left child ready. Current time: 6.0566 seconds\n",
      "Right child ready. Current time: 6.0566 seconds\n",
      "Left child ready. Current time: 9.5308 seconds\n",
      "Right child ready. Current time: 9.5309 seconds\n",
      "Right child ready. Current time: 12.8646 seconds\n",
      "Right child ready. Current time: 349.2171 seconds\n",
      "Left child ready. Current time: 376.2660 seconds\n",
      "Right child ready. Current time: 376.2661 seconds\n",
      "Right child ready. Current time: 414.8609 seconds\n",
      "Left child ready. Current time: 459.7957 seconds\n",
      "Computing best feature... Depth: 19\n",
      "Best feature found in 12.3426 seconds: Psi_eta, division_point: 117862.                      \n",
      "Creating childs...\n",
      "Computing best feature... Depth: 18\n",
      "Best feature found in 7.0097 seconds: Freq3_harmonics_amplitude_0, division_point: 16709.    \n",
      "Creating childs...\n",
      "Computing best feature... Depth: 17\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best feature found in 6.9162 seconds: Autocor_length, division_point: 27288.                 \n",
      "Creating childs...\n",
      "Computing best feature... Depth: 16\n",
      "Best feature found in 4.5735 seconds: Period_fit, division_point: 35350.                     \n",
      "Creating childs...\n",
      "Computing best feature... Depth: 15\n",
      "Best feature found in 3.7735 seconds: SlottedA_length, division_point: 16632.                \n",
      "Creating childs...\n",
      "Left child ready. Current time: 3.7948 seconds\n",
      "Computing best feature... Depth: 14\n",
      "Best feature found in 3.1337 seconds: Autocor_length, division_point: 41974.                 \n",
      "Creating childs...\n",
      "Left child ready. Current time: 3.1511 seconds\n",
      "Right child ready. Current time: 3.1512 seconds\n",
      "Right child ready. Current time: 6.9464 seconds\n",
      "Left child ready. Current time: 11.5437 seconds\n",
      "Right child ready. Current time: 11.5438 seconds\n",
      "Left child ready. Current time: 18.4950 seconds\n",
      "Right child ready. Current time: 18.4951 seconds\n",
      "Left child ready. Current time: 25.5417 seconds\n",
      "Right child ready. Current time: 25.5418 seconds\n",
      "Left child ready. Current time: 37.9521 seconds\n",
      "Computing best feature... Depth: 18\n",
      "Best feature found in 5.2327 seconds: Psi_eta, division_point: 6433.                         \n",
      "Creating childs...\n",
      "Computing best feature... Depth: 17\n",
      "Best feature found in 2.7715 seconds: Psi_CS, division_point: 84934.                         \n",
      "Creating childs...\n",
      "Left child ready. Current time: 2.7938 seconds\n",
      "Right child ready. Current time: 2.7940 seconds\n",
      "Left child ready. Current time: 8.0534 seconds\n",
      "Computing best feature... Depth: 17\n",
      "Best feature found in 2.8770 seconds: Psi_CS, division_point: 190292.                        \n",
      "Creating childs...\n",
      "Left child ready. Current time: 2.8926 seconds\n",
      "Right child ready. Current time: 2.8927 seconds\n",
      "Right child ready. Current time: 10.9465 seconds\n",
      "Right child ready. Current time: 48.8995 seconds\n",
      "Right child ready. Current time: 508.6968 seconds\n"
     ]
    }
   ],
   "source": [
    "regression_tree = fit(train, 'PeriodLS', 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualización"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "from graphviz import Digraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generador_ids():\n",
    "    i = 0\n",
    "    while True:\n",
    "        yield i\n",
    "        i += 1    \n",
    "    \n",
    "g = generador_ids()\n",
    "def make_graph(tree, graph):\n",
    "\n",
    "    text1 = '{}\\n{:.5f}'.format(tree.feature, tree.division_point)\n",
    "    \n",
    "    if not tree.left_child.leaf:\n",
    "        text_left = '{}\\n{:.5f}'.format(tree.left_child.feature, tree.left_child.division_point)\n",
    "        graph.edge(text1, text_left)\n",
    "        make_graph(tree.left_child, graph)\n",
    "    else:\n",
    "        graph.edge(text1, 'hoja N{}'.format(next(g)))\n",
    "    \n",
    "    if not tree.right_child.leaf:\n",
    "        text_right = '{}\\n{:.5f}'.format(tree.right_child.feature, tree.right_child.division_point)\n",
    "        graph.edge(text1, text_right)\n",
    "        make_graph(tree.right_child, graph)\n",
    "    else:\n",
    "        graph.edge(text1, 'hoja N{}'.format(next(g)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'regression_tree.gv.pdf'"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "u = Digraph('regression_tree', filename='regression_tree.gv')\n",
    "u.attr(size='6,6')\n",
    "u.node_attr.update(color='lightblue2', style='filled')\n",
    "    \n",
    "make_graph(regression_tree, u)\n",
    "\n",
    "u.view()  # LAS HOJAS NO SE MUESTRAN EN LA VISUALIZACION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "def execute_test(test_set, tree, target='PeriodLS'):\n",
    "    t0 = time()\n",
    "    length = len(test_set)\n",
    "    sse = 0\n",
    "    for i in range(length):\n",
    "        row = test_set.iloc[i]\n",
    "        sse += (predict(row, tree) - row[target])**2\n",
    "        if i % 10 == 0:\n",
    "            print('Seconds left: {:.2f}...'.format((time()-t0)/(i+1) * (length-i-1)), end='\\r')\n",
    "    mse = sse / length\n",
    "    print('Test finished in {:.2f} seconds.\\nMSE: {:.3f}\\nsqrtMSE: {:.3f}'.format(time()-t0, mse, mse**(1/2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test finished in 38.56 seconds.\n",
      "MSE: 52445.189\n",
      "STD: 229.009\n"
     ]
    }
   ],
   "source": [
    "execute_test(test, regression_tree40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explicación"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Al aplicar el modelo al conjunto de test, se calculó la distancia de cada predicción al valor real, y con esto se calculó el error cuadrático medio (MSE). El MSE es una buena manera de evaluar al modelo, ya que es comparable con la varianza de los datos crudos. Por ejemplo, a continuación calculamos la dispersión de los datos sin procesar:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "276.8663345620412"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['PeriodLS'].std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este valor se puede interpretar como la raíz del MSE que obtendría un modelo que simplemente predice la media de los datos, independiente del input, ya que que si la predicción es siempre el promedio, el MSE estará calculando la dispersión con respecto a la media. Si comparamos este valor con la raiz del MSE del modelo, vemos que el modelo logra acercarse más a los valores reales que si solo se adivinara con el valor de la media general. Esta información nos dice directamente que el modelo sirve de cierto modo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con respecto a los distintos valores que se le pueden asignar a la profundidad maxima del arbol, podemos deducir que mientras más profundidad, hay mayor overfitting, por lo que el modelo tendería a ser más preciso, pero solo hasta cierto punto de inflexión, en el cual se empezaría a sesgar el modelo \"aprendiendose\" el set de training. Desde este punto el testeo comenzaria a mostrar valores de MSE más altos.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
